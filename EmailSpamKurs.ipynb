{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7895d17d-c9c7-427d-aaf8-cc3a0420acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "class Data:\n",
    "    \"\"\" A util class to store the training and test datasets. \"\"\"\n",
    "    \n",
    "    def __init__(self, tr_explanatory: pd.DataFrame, tr_explained: pd.DataFrame, \n",
    "                test_explanatory: pd.DataFrame, test_explained: pd.DataFrame):\n",
    "        \n",
    "        self.tr_explanatory = tr_explanatory\n",
    "        self.tr_explained = tr_explained\n",
    "        self.test_explanatory = test_explanatory\n",
    "        self.test_explained = test_explained\n",
    "    \n",
    "    def consistency_check(self):\n",
    "        print(\"Shape EXPLANATORY (Training set): {}\".format(self.tr_explanatory.shape))\n",
    "        print(\"Shape EXPLAINED (Training set): {}\".format(self.tr_explained.shape))\n",
    "        print(\"Shape EXPLANATORY (Test set): {}\".format(self.test_explanatory.shape))\n",
    "        print(\"Shape EXPLAINED (Test set): {}\".format(self.test_explained.shape))\n",
    "        \n",
    "        if self.tr_explanatory.shape[0] == self.tr_explained.shape[0] and \\\n",
    "            self.test_explanatory.shape[0] == self.test_explained.shape[0] and \\\n",
    "            self.tr_explanatory.shape[1] == self.test_explanatory.shape[1] :\n",
    "            print(\"Consistent dimensions.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"ERROR: Inconsistent dimensions!\")\n",
    "            print(self.tr_explanatory.shape[0] == self.tr_explained.shape[0])\n",
    "            print(self.test_explanatory.shape[0] == self.test_explained.shape[0])\n",
    "            print(self.tr_explanatory.shape[1] == self.test_explanatory.shape[1])\n",
    "            return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81dd18c6-79d0-4f65-a407-0d91d62ffb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV file\n",
    "data = pd.read_csv('../shuffle_email_spam_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ae6e3bd-5f0b-4688-bbc0-f8aa8b4c858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5172 entries, 0 to 5171\n",
      "Columns: 3002 entries, Email No. to Prediction\n",
      "dtypes: int64(3001), object(1)\n",
      "memory usage: 118.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       " 0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       " 1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       " 2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       " 3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       " 4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       " \n",
       "    valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       " 0       0    0               0         0         0   0    0           0  \n",
       " 1       0    0               0         0         0   1    0           0  \n",
       " 2       0    0               0         0         0   0    0           0  \n",
       " 3       0    0               0         0         0   0    0           0  \n",
       " 4       0    0               0         0         0   1    0           0  \n",
       " \n",
       " [5 rows x 3002 columns],\n",
       " None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(), data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "664ce442-a61b-4e0f-b46e-a5260afe1e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape EXPLANATORY (Training set): (3879, 3000)\n",
      "Shape EXPLAINED (Training set): (3879,)\n",
      "Shape EXPLANATORY (Test set): (1293, 3000)\n",
      "Shape EXPLAINED (Test set): (1293,)\n",
      "Consistent dimensions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing\n",
    "# Step 1: Remove the \"Email No.\" column\n",
    "data_cleaned = data.drop(columns=[\"Email No.\"])\n",
    "data_cleaned = data_cleaned.sample(frac=1).reset_index(drop=True)\n",
    "n = data_cleaned.shape[0]\n",
    "thr = math.floor(0.75 * n)\n",
    "\n",
    "X_train = data_cleaned.iloc[:thr, :-1]\n",
    "Y_train = data_cleaned.iloc[:thr, -1]\n",
    "X_test = data_cleaned.iloc[thr:, :-1]\n",
    "Y_test = data_cleaned.iloc[thr:, -1]\n",
    "\n",
    "#Data object\n",
    "yy = Data(X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "yy.consistency_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d677bbb5-c7c7-412b-aa23-0c3c374ce461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions: [0 0 1 ... 1 1 1] \n",
      "\n",
      "\n",
      "\n",
      "      LogPredict  Actual\n",
      "3879           0       0\n",
      "3880           0       0\n",
      "3881           1       1\n",
      "3882           0       0\n",
      "3883           0       0\n",
      "...          ...     ...\n",
      "5167           0       0\n",
      "5168           0       0\n",
      "5169           1       1\n",
      "5170           1       1\n",
      "5171           1       1\n",
      "\n",
      "[1293 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize Logistic Regression with increased max_iter and solver\n",
    "logreg = LogisticRegression(max_iter=500, solver='lbfgs')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(yy.tr_explanatory)\n",
    "X_test_scaled = scaler.transform(yy.test_explanatory)\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train_scaled, yy.tr_explained)\n",
    "\n",
    "#Predict the fitted data\n",
    "predictions_LR = logreg.predict(X_test_scaled)\n",
    "\n",
    "print(\"All predictions: {0} \\n\\n\\n\".format(predictions_LR))\n",
    "pred_vs_actual_LR_df = pd.DataFrame({\n",
    "    \"LogPredict\": predictions_LR,\n",
    "    \"Actual\": yy.test_explained\n",
    "})\n",
    "\n",
    "# pred_vs_actual_LR_df = pd.DataFrame(X_test_scaled, columns=[f'Feature_{i+1}' for i in range(X_test_scaled.shape[1])])\n",
    "# pred_vs_actual_LR_df['LogPredict'] = predictions_LR\n",
    "# pred_vs_actual_LR_df['Actual'] = yy.test_explained\n",
    "\n",
    "print(pred_vs_actual_LR_df)\n",
    "# X, Y = make_classification(random_state=42)\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "# pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "# pipe.fit(X_train, Y_train)  # apply scaling on training data\n",
    "# pipe.score(X_test, Y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0a175-6167-4348-9316-db5fc6507301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualize both the Training and the Test set\n",
    "plt.scatter(yy.tr_explanatory.iloc[:, 0], yy.tr_explanatory.iloc[:, 1], c = yy.tr_explained, marker=\"x\")\n",
    "\n",
    "# Create a new column with custom colors: Green for class \"1\"; Blue for class \"0\" \n",
    "pred_vs_actual_LR_df['CLass-Color'] = pred_vs_actual_LR_df['LogPredict'].apply(lambda x: 'Green' if x == 1 else 'Blue')\n",
    "\n",
    "plt.scatter(\n",
    "    pred_vs_actual_LR_df.iloc[:, 0], \n",
    "    pred_vs_actual_LR_df.iloc[:, 1], \n",
    "    c=pred_vs_actual_LR_df[\"CLass-Color\"], \n",
    "    marker=\"o\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49d38a52-3e69-4927-88f9-00e58118cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[902  31]\n",
      " [ 17 343]]\n",
      "\n",
      "#####   Accuracy: 96.2877030162413 %   ##### \n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       933\n",
      "           1       0.92      0.95      0.93       360\n",
      "\n",
      "    accuracy                           0.96      1293\n",
      "   macro avg       0.95      0.96      0.95      1293\n",
      "weighted avg       0.96      0.96      0.96      1293\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "confusion_mtx_LR = confusion_matrix(yy.test_explained, predictions_LR)\n",
    "print(\"Confusion matrix: \\n{}\".format(confusion_mtx_LR))\n",
    "\n",
    "# Get only the Accuracy\n",
    "ACC = classification_report(yy.test_explained, predictions_LR, output_dict=True)['accuracy']\n",
    "print(\"\\n#####   Accuracy: {} %   ##### \\n\\n\\n\".format(ACC*100))\n",
    "\n",
    "# Get all stats\n",
    "print(classification_report(yy.test_explained, predictions_LR, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452e6a0-e281-4b24-91c8-899ca426cb87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
